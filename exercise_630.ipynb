{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier for Toy Problem 3\n",
    "\n",
    "Now let's build a classifier for Toy Problem 3.\n",
    "\n",
    "We've provided a utility class 'Data' (in data_reader.py) to load the training data (it works for all the toy problems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "Features:\n",
      "[[59, -85], [-97, 67], [-93, 31], [31, -73], [-29, 69], [-31, -10], [-62, 64], [11, 21], [63, 69], [-21, 79]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_reader import Data\n",
    "\n",
    "data = Data(\"data/toy_problem_3_train.txt\")\n",
    "\n",
    "labels, features = data.get_sample()\n",
    "\n",
    "print(\"Labels:\\n\"+str(labels))\n",
    "\n",
    "print(\"Features:\\n\"+str(features))\n",
    "    \n",
    "target = torch.autograd.Variable(torch.LongTensor(labels))\n",
    "#print(\"Labels Tensor:\\n\"+str(target))\n",
    "\n",
    "features = torch.autograd.Variable(torch.Tensor(features))\n",
    "#print(\"Features Tensor:\\n\"+str(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the weights randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.5054  0.7487\n",
      " 0.0225  0.4477\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = torch.nn.Parameter(torch.rand(2, 2))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform 100 learning iterations below as many times as we want.\n",
    "\n",
    "Notice that the code for the learning iterations is identical to that of exercise 530."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is now 2.601632833480835\n",
      "The loss is now 2.004544734954834\n",
      "The loss is now 12.074604034423828\n",
      "The loss is now 11.238866806030273\n",
      "The loss is now 5.32888650894165\n",
      "The loss is now 6.22322416305542\n",
      "The loss is now 10.873896598815918\n",
      "The loss is now 1.5366473197937012\n",
      "The loss is now 2.999246597290039\n",
      "The loss is now 10.520666122436523\n",
      "The loss is now 12.201106071472168\n",
      "\tThe weights are now \n",
      " 0.5275  0.7267\n",
      " 0.0379  0.4323\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    labels, features = data.get_sample(10)\n",
    "    \n",
    "    features = torch.autograd.Variable(torch.Tensor(features))\n",
    "    #print(data)\n",
    "    \n",
    "    target = torch.autograd.Variable(torch.LongTensor(labels))\n",
    "    #print(target)\n",
    "    \n",
    "    result = torch.mm(features, weights)\n",
    "    #print(result)\n",
    "    \n",
    "    loss = F.cross_entropy(result, target)\n",
    "    #print(\"Cross entropy loss: \"+str(loss))\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    gradient = weights.grad\n",
    "    \n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    weights.data = weights.data - learning_rate * gradient.data\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"The loss is now \"+str(loss.data[0]))\n",
    "    \n",
    "    weights.grad.data.zero_()\n",
    "\n",
    "print(\"\\tThe weights are now \"+str(weights.data))\n",
    "\n",
    "torch.save(weights, \"models/toy_problem_3_trained_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Loss\n",
    "\n",
    "Observe the loss that is printed at the end of every 10 iterations.\n",
    "\n",
    "Now matter how many hundreds of times you run the hill-climbing code, the loss does not decrease.\n",
    "\n",
    "This tells us that the machine learning algorithm is probably not learning anthing much.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "You can try find the parameters manually.  We know that the matrix should be a 2x2 matrix like this.\n",
    "\n",
    "$$\\begin{bmatrix}w_{0,0} & w_{0,1} \\\\ w_{1,0} & w_{1,1} \\end{bmatrix}$$\n",
    "\n",
    "But we won't be able to come up with a good set of values that works well on this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Test - Toy Problem 3\n",
    "\n",
    "We have just trained a classifier for Toy Problem 3.\n",
    "\n",
    "It doesn't seem to be learning anything (the loss on the training data does not decrease).\n",
    "\n",
    "But, to make sure, let us evaluate the performance of the classifier on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.5275  0.7267\n",
      " 0.0379  0.4323\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Accuracy: 0.517\n"
     ]
    }
   ],
   "source": [
    "data = Data(\"data/toy_problem_3_test.txt\")\n",
    "\n",
    "weights = torch.load(\"models/toy_problem_3_trained_model.bin\")\n",
    "print(weights)\n",
    "\n",
    "labels, features = data.get_all()\n",
    "\n",
    "features = torch.autograd.Variable(torch.Tensor(features))\n",
    "#print(features)\n",
    "\n",
    "target = torch.autograd.Variable(torch.LongTensor(labels))\n",
    "#print(target)\n",
    "\n",
    "result = torch.mm(features, weights)\n",
    "#print(result)\n",
    "\n",
    "maxv, observed = torch.max(result, 1)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(labels)):\n",
    "    total += 1\n",
    "    #print(str(target.data[i]) + \" \" + str(observed.data[i]))\n",
    "    if target.data[i] == observed.data[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / total\n",
    "print(\"Accuracy: \"+str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see, the accuracy is 50%.\n",
    "\n",
    "50% accuracy on a 2-class classification problem is not a good score because you can get that score by randomly tossing a coin and using it to pick your categories.\n",
    "\n",
    "Why is the performance of the single-layer neural network so bad?\n",
    "\n",
    "The slides of the course will tell you the reason (starting from slide 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
